---
title: "Wordvectors Exploration with visualizations"
author: "Shantam Gupta"
date: "April 8, 2017"
output:
  html_document: default
---
```{r}
require(dplyr)
require(wordVectors)
require(tsne)
```
#looking at words closest to true and false 
```{r}
words = c("true","false")
term_set = lapply(words, 
       function(ingredient) {
          nearest_words = trainComments %>% closest_to(trainComments[[ingredient]],20)
          nearest_words$word
        }) %>% unlist

subset = trainComments[[term_set,average=F]]

subset %>%
  cosineDist(subset) %>% 
  as.dist %>%
  hclust %>%
  plot

```


#TSNE Dimensionality reduction  (for visualizing similar sentiment words in low dimensional space)
```{r}
plot(trainComments,perplexity=50)
```
 
To learn more about TSNE : https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding

 
#Clustering vectorsapce model with knn
```{r}
set.seed(10)
centers = 10
clustering = kmeans(trainComments,centers=centers,iter.max = 40)
#selecting 10 random clusters and looking at the top 10 words closest to it 
sapply(sample(1:centers,10),function(n) {
  names(clustering$cluster[clustering$cluster==n][1:10])
})
```
#looking at cosine similarity distances for vectors  of  true and false
```{r}
# traincomments[1:3000,] here restricts to the 3000 most common words in the set.
common_similarities_true = trainComments[1:3000, ] %>% cosineSimilarity(trainComments[[c("true","false"),average = F]])

high_similarities_to_true= common_similarities_true[rank(-apply(common_similarities_true,1,max)) < 15,]

high_similarities_to_true %>% 
  prcomp %>% 
  biplot(main="words in a projection of true & false ")
```

#looking at cosine similarity between tue and  false
```{r}
cosineSimilarity(trainComments[[c("true"),average=F]], trainComments[[c("false"),average=F]])
```

This value is small, which leaves room for separation of the "true" and "false"  vectors.